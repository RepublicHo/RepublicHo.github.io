<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>URIS Project Website</title>
    <link rel="stylesheet" type="text/css" href="main.css">
    <style type="text/css">
        .footer-images {
            text-align: center;
            margin-top: 20px;
            margin-bottom: 20px;
        }
        
        .footer-images img {
            width: 285px;
            height: 80px;
            margin: 0 25px;
        }
    </style>
</head>


<body>
    <div id="container">
        <!-- Structure of the Page -->
        <header>
            <h1 class="site-title">Efficient Hybrid Search in Vector Database</h1>

        </header>

        <h2>Authors</h2>
        <div class="author-info">
            <p>
                Zhilin GAO (zhilin.gao@connect.polyu.hk)
            </p>
            <p>
                Zhejun HE (zhejun.he@connect.polyu.hk)
            </p>
            <p>
                Dr Ken YIU (csmlyiu@comp.polyu.edu.hk)
            </p>
        </div>

        <h2>Introduction</h2>
        <p align="justify">
            This project is inspired by a research project conducted at Alibaba. With recent advancements in machine learning and representation learning, querying and analyzing either structured or unstructured data alone has become comparatively easy nowadays.
            In practice, however, queries in analytical databases usually involve both structured and unstructured data. We noted that it remains a challenge in the industry to enable searching structured (i.e., related attributes) and unstructured data
            (i.e., feature vectors) in a hybrid and efficient manner. This research project aims to investigate and propose a better solution in this regard and developed a demo system.
        </p>
        <h2>Research output</h2>
        <p align="justify">Technical Report. </p>
        <p align="justify">Quantization-based method has been adopted by Alibaba and Milvus, and we conduct relevant research. Study: [<a href="./resources/product quantization.pdf">link</a>]</p>

        <h2>Our proposed methods</h2>
        <p align="justify">We took advantage of Approximate Nearest Neighbor Search (ANNs) and implemented both VP-tree and Product Quantization (PQ) methods to expedite hybrid search. In the case of VP-tree, instead of reckoning vector search and attribute filtering as
            distinct stages, we proposed a simultaneous application of both criteria. Our research has demonstrated the superior performance of the concurrent hybrid search method in VP-tree compared to the pre-query and post-query methods. </p>
        <p align="justify">Regarding PQ, we proposed the utilization of a pre-query method that allows attribute filtering to be performed prior to distance calculation between each query vector and the corresponding pq-code. And importantly, pre-query would not compromise
            the result of Top-K retrieval. We observe that incorporating attribute filtering before the distance calculation process significantly improves the overall efficiency of the search, considering metrics such as speed and resource utilization.
        </p>

        <h2>Demo system</h2>
        <p align="justify"><a href="https://connectpolyu-my.sharepoint.com/:v:/g/personal/20084054d_connect_polyu_hk/ESdkK-WxpcVLmkY5PsCh4SIBWV56KonYMwo0UnOBz5p0ng?e=JKCTmt&nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJTdHJlYW1XZWJBcHAiLCJyZWZlcnJhbFZpZXciOiJTaGFyZURpYWxvZyIsInJlZmVycmFsQXBwUGxhdGZvcm0iOiJXZWIiLCJyZWZlcnJhbE1vZGUiOiJ2aWV3In19">Video Link</a>            (This demo system is only used for testing numerous hybrid search methods with VP-tree and PQ, where text and image size is considered as structured data.) </p>

        <div class="footer-images">
            <img src="./figs/Graduate School logo.png" alt="Footer Image 1">
            <img src="./figs/polyu.png" alt="Footer Image 2">
        </div>

        <footer>
            <p></p>
            <em>Copyright &copy; 2022-2023 Zhejun, Zhilin.</em>
        </footer>
    </div>

</body>

</html>